{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CrBOgQxBfYg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/IZ-f-AI-ss3/Denoising_in_score_based_generative_models.git\n",
        "%cd /content/Denoising_in_score_based_generative_models/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5qamj8GRMARN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install tensorboardX  # pyyaml\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/Denoising_in_score_based_generative_models')\n",
        "\n",
        "!gdown https://drive.google.com/uc?id=1BF2mwFv5IRCGaQbEWTbLlAOWEkNzMe5O\n",
        "!unzip cifar10.zip -d /content/Denoising_in_score_based_generative_models/run/logs\n",
        "!unzip run.zip -d /content/Denoising_in_score_based_generative_models/\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z2fxOKKbCf8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --runner AnnealRunner --test -o samples  --doc celeba --sampling half_initial_denoising\n",
        "\n",
        "# !python main.py --runner AnnealRunner --heavy_test -o samples --doc cifar10 --n_samples 200 --sampling_type half_denoising # ordinary #50000\n",
        "\n",
        "# Warning : it took 15 minutes for 2 batchs (200 samples) and we need 50k samples ???"
      ],
      "metadata": {
        "id": "VT7MnprG1TBS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\n",
        "    \"half_denoising\",\n",
        "    \"zip\",\n",
        "    \"/content/Denoising_in_score_based_generative_models/samples/half_denoising\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "e8NpyQL377K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"half_denoising.zip\")"
      ],
      "metadata": {
        "id": "lGueditY7-N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r samples.zip /content/Denoising_in_score_based_generative_models/samples/"
      ],
      "metadata": {
        "id": "uiqvYlFU1xiS",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('samples.zip')"
      ],
      "metadata": {
        "id": "iOeZhTG12A_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-fidelity"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AYqbflR4sy-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/samples_ordinary_mnist_10k.zip\n",
        "# !unzip /content/samples_ordinary_mnist_10k.zip -d /content/\n",
        "!unzip /content/whole_celeba_kaggle.zip -d /content/\n",
        "\n",
        "# !unzip samples_debug.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "We6rmPiHtDE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "\n",
        "tran_transform = transforms.Compose([\n",
        "                transforms.Resize(28), # 32 for the others\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "mnist_dataset = datasets.MNIST(\n",
        "    root='/content/data/mnist',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=tran_transform\n",
        ")\n",
        "\n",
        "mnist_folder = '/content/data/mnist_for_fid'\n",
        "os.makedirs(mnist_folder, exist_ok=True)\n",
        "\n",
        "for i, (img, _) in enumerate(mnist_dataset):\n",
        "    save_image(img, os.path.join(mnist_folder, f\"{i}.png\"))"
      ],
      "metadata": {
        "id": "id38xColhz6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "from torchvision import transforms, datasets\n",
        "import os\n",
        "\n",
        "tran_transform = transforms.Compose([\n",
        "                transforms.Resize(28), # 32 for the others\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "cifar_dataset = datasets.CIFAR10(\n",
        "    root='/content/data/cifar',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=tran_transform\n",
        ")\n",
        "\n",
        "cifar_folder = '/content/data/cifar_for_fid'\n",
        "os.makedirs(mnist_folder, exist_ok=True)\n",
        "\n",
        "for i, (img, _) in enumerate(mnist_dataset):\n",
        "    save_image(img, os.path.join(mnist_folder, f\"{i}.png\"))\n"
      ],
      "metadata": {
        "id": "rk6iYLqzv_S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Unzip the file\n",
        "zip_path = '/content/whole_celeba_kaggle.zip'\n",
        "extract_path = '/content/celeba_extracted_3'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(140),\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(\n",
        "    root=extract_path,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "celeba_folder = '/content/data/celeba_for_fid_3'\n",
        "os.makedirs(celeba_folder, exist_ok=True)\n",
        "\n",
        "# 5. Save images\n",
        "print(f\"Saving images to {celeba_folder}...\")\n",
        "for i in tqdm(range(len(dataset)), desc=\"Processing\"):\n",
        "    img, _ = dataset[i]\n",
        "    save_image(img, os.path.join(celeba_folder, f\"{i}.png\"))\n",
        "\n",
        "print(f\"Success! {len(dataset)} images saved.\")"
      ],
      "metadata": {
        "id": "JQ21XLHHbx-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import torch\n",
        "# from torchvision import datasets, transforms\n",
        "# from torchvision.utils import save_image\n",
        "# from tqdm import tqdm # Useful for tracking progress\n",
        "\n",
        "# # 1. Define Transforms\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.CenterCrop(140),\n",
        "#     transforms.Resize(32),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "# # 2. Load CelebA dataset\n",
        "# # Note: If download=True fails, you must manually download the files\n",
        "# # (img_align_celeba.zip and identity_CelebA.txt, etc.) into /content/data/celeba/\n",
        "# try:\n",
        "#     celeba_dataset = datasets.CelebA(\n",
        "#         root='/content/data',\n",
        "#         split='train',\n",
        "#         transform=transform,\n",
        "#         download=True\n",
        "#     )\n",
        "# except RuntimeError as e:\n",
        "#     print(f\"Download failed: {e}\")\n",
        "#     print(\"Tip: CelebA download limits are often reached. You may need to manual download.\")\n",
        "\n",
        "# # 3. Setup output folder\n",
        "# celeba_folder = '/content/data/celeba_for_fid'\n",
        "# os.makedirs(celeba_folder, exist_ok=True)\n",
        "\n",
        "# # 4. Save images (using tqdm to see progress)\n",
        "# print(f\"Saving images to {celeba_folder}...\")\n",
        "# for i, (img, _) in enumerate(tqdm(celeba_dataset)):\n",
        "#     save_image(img, os.path.join(celeba_folder, f\"{i}.png\"))\n",
        ""
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z38Bizwjo2EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_fidelity\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "file_path_ordinary = \"/content/kaggle/working/Denoising_in_score_based_generative_models/samples/ordinary/\"\n",
        "# file_path_half_denoising = \"/content/celeba-half-denoising-7501\"\n",
        "\n",
        "print(f\"Metrics calculation using image folder: {file_path_ordinary}\")\n",
        "\n",
        "print(\"\\n--- Results for Ordinary Sampling ---\")\n",
        "metrics_ord = torch_fidelity.calculate_metrics(\n",
        "    input1=file_path_ordinary,\n",
        "    input2=celeba_folder,\n",
        "    cuda=True,\n",
        "    fid=True,\n",
        "    isc=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"-------------------------------------------------------\")\n",
        "print('-------------------------------------------------------')\n",
        "print(f\"FID: {metrics_ord['frechet_inception_distance']:.4f}\")\n",
        "print(f\"IS:  {metrics_ord['inception_score_mean']:.4f} ± {metrics_ord['inception_score_std']:.4f}\")"
      ],
      "metadata": {
        "id": "rqT_aYRQdJUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jscJ4Ak_ZYHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch_fidelity\n",
        "# from torch.utils.data import TensorDataset\n",
        "\n",
        "# _original_load = torch.serialization.load\n",
        "# def fixed_load(*args, **kwargs):\n",
        "#     kwargs.setdefault(\"weights_only\", False)\n",
        "#     return _original_load(*args, **kwargs)\n",
        "\n",
        "# torch.load = fixed_load\n",
        "\n",
        "# file_path_ordinary = \"/content/kaggle/working/Denoising_in_score_based_generative_models/samples/ordinary\"\n",
        "# # file_path_ordinary = \"/content/Denoising_in_score_based_generative_models/samples/ordinary.pt\"\n",
        "# # file_path_half = \"/content/Denoising_in_score_based_generative_models/samples/half_denoising.pt\"\n",
        "\n",
        "# print(\"Loading sample tensors from .pt files...\")\n",
        "\n",
        "# samples_ord_tensor = torch.load(file_path_ordinary)\n",
        "# # samples_half_tensor = torch.load(file_path_half)\n",
        "\n",
        "# # if samples_ord_tensor.dtype != torch.uint8:\n",
        "# #     samples_ord_tensor = (samples_ord_tensor * 255).clamp(0, 255).to(torch.uint8)\n",
        "# # if samples_half_tensor.dtype != torch.uint8:\n",
        "# #     samples_half_tensor = (samples_half_tensor * 255).clamp(0, 255).to(torch.uint8)\n",
        "\n",
        "# if samples_ord_tensor.dim() == 4 and samples_ord_tensor.size(1) == 1:\n",
        "#     samples_ord_tensor = samples_ord_tensor.repeat(1, 3, 1, 1)\n",
        "# elif samples_ord_tensor.dim() != 4 or samples_ord_tensor.size(1) not in (1, 3):\n",
        "#     raise ValueError(f\"Unexpected tensor shape for image data: {samples_ord_tensor.shape}\")\n",
        "\n",
        "\n",
        "# ds_ordinary = TensorDataset(samples_ord_tensor)\n",
        "# # ds_half = TensorDataset(samples_half_tensor)\n",
        "\n",
        "\n",
        "\n",
        "# print(\"\\n--- Results for Ordinary Sampling ---\")\n",
        "# metrics_ord = torch_fidelity.calculate_metrics(\n",
        "#     input1= ds_ordinary,\n",
        "#     input2=\"cifar10-train\",\n",
        "#     cuda=True,\n",
        "#     fid=True,\n",
        "#     isc=True,\n",
        "#     verbose=False\n",
        "# )\n",
        "# print(f\"FID: {metrics_ord['frechet_inception_distance']:.4f}\")\n",
        "# print(f\"IS:  {metrics_ord['inception_score_mean']:.4f} ± {metrics_ord['inception_score_std']:.4f}\")\n",
        "\n",
        "# # print(\"\\n--- Results for Half-Denoising ---\")\n",
        "# # metrics_half = torch_fidelity.calculate_metrics(\n",
        "# #     input1=ds_half,\n",
        "# #     input2=\"cifar10-train\",\n",
        "# #     cuda=True,\n",
        "# #     fid=True,\n",
        "# #     isc=True,\n",
        "# #     verbose=False\n",
        "# # )\n",
        "# # print(f\"FID: {metrics_half['frechet_inception_distance']:.4f}\")\n",
        "# # print(f\"IS:  {metrics_half['inception_score_mean']:.4f} ± {metrics_half['inception_score_std']:.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UWrz-Hj84PZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch_fidelity\n",
        "\n",
        "# _original_load = torch.load\n",
        "\n",
        "# def fixed_load(*args, **kwargs):\n",
        "#     # Inject weights_only=False if it's missing\n",
        "#     if 'weights_only' not in kwargs:\n",
        "#         kwargs['weights_only'] = False\n",
        "#     return _original_load(*args, **kwargs)\n",
        "\n",
        "# torch.load = fixed_load\n",
        "\n",
        "# path_ordinary = \"/content/content/Denoising_in_score_based_generative_models/samples/ordinary\"\n",
        "# path_half = \"/content/content/Denoising_in_score_based_generative_models/samples/half_denoising\"\n",
        "\n",
        "# print(\"--- Results for Ordinary Sampling ---\")\n",
        "# metrics_ord = torch_fidelity.calculate_metrics(\n",
        "#     input1=path_ordinary,\n",
        "#     input2=\"cifar10-train\",\n",
        "#     cuda=True,\n",
        "#     fid=True,\n",
        "#     isc=True,\n",
        "#     verbose=False\n",
        "# )\n",
        "# print(f\"FID: {metrics_ord['frechet_inception_distance']:.4f}\")\n",
        "# print(f\"IS:  {metrics_ord['inception_score_mean']:.4f} ± {metrics_ord['inception_score_std']:.4f}\")\n",
        "\n",
        "# print(\"\\n--- Results for Half-Denoising ---\")\n",
        "# metrics_half = torch_fidelity.calculate_metrics(\n",
        "#     input1=path_half,\n",
        "#     input2=\"cifar10-train\",\n",
        "#     cuda=True,\n",
        "#     fid=True,\n",
        "#     isc=True,\n",
        "#     verbose=False\n",
        "# )\n",
        "# print(f\"FID: {metrics_half['frechet_inception_distance']:.4f}\")\n",
        "# print(f\"IS:  {metrics_half['inception_score_mean']:.4f} ± {metrics_half['inception_score_std']:.4f}\")\n",
        "\n",
        "# # # 1. Calculate for Ordinary Sampling\n",
        "# # print(\"--- Results for Ordinary Sampling ---\")\n",
        "# # !fidelity --gpu 0 --fid --isc --input1 \"/content/content/Denoising_in_score_based_generative_models/samples/ordinary\" --input2 cifar10-train\n",
        "\n",
        "# # # 2. Calculate for Half-Denoising Sampling\n",
        "# # print(\"\\n--- Results for Half-Denoising ---\")\n",
        "# # !fidelity --gpu 0 --fid --isc --input1 \"/content/content/Denoising_in_score_based_generative_models/samples/half_denoising\" --input2 cifar10-train"
      ],
      "metadata": {
        "id": "0UVpINwuszwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gK64UiFtZ7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}